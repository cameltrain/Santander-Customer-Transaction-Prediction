{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa44d3d09a93efc6e27432ce40d412b781153a2f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4c5d0b42a79c143d4b1a0423b0c51265fd718fd"
   },
   "source": [
    "# <a id='2'>Prepare for data analysis</a>  \n",
    "\n",
    "\n",
    "## Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2041989e97107b61bb6659706ead46cc448c8e9e"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13cdc14c0a53b11fd7438a87bff04335666a5482"
   },
   "source": [
    "## Load data   \n",
    "\n",
    "Let's check what data files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "80167a92eedaecb6878667e35c55e4dbf8d3dc20"
   },
   "outputs": [],
   "source": [
    "PATH=\"../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a37cbcca50a9993268b90dbb9ab6ddb72be0632c"
   },
   "source": [
    "Let's load the train and test data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "cdd6627b37c9b162dd2d7f677576c94e35571fd8"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(PATH+\"train.csv\")\n",
    "test_df = pd.read_csv(PATH+\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c026a2812283de0951bd65dab107cdac65de718"
   },
   "source": [
    "# <a id='3'>Data exploration</a>  \n",
    "\n",
    "## <a id='31'>Check the data</a>  \n",
    "\n",
    "Let's check the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "b3034013c64910fb504a5e06f125e6a8907b4822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 201))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a78f8652d9b1746d7b806520bc5c95cbfd4e98eb"
   },
   "source": [
    "Both train and test data have 200,000 entries and 202, respectivelly 201 columns. \n",
    "\n",
    "Let's glimpse train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "9ef17fbff9c4911a15603c9d40833c5b70ac6da3"
   },
   "outputs": [],
   "source": [
    "\n",
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "for feature in features:\n",
    "    train_df[feature] = np.power(train_df[feature],2)\n",
    "    test_df[feature] = np.power(test_df[feature],2)\n",
    "    #train_df['l_'+feature] = np.log(train_df[feature])\n",
    "    #test_df['l_'+feature] = np.log(test_df[feature])\n",
    "    #train_df['p2_'+feature] = np.power(train_df[feature], 2)\n",
    "    #test_df['p2_'+feature] = np.power(test_df[feature], 2)\n",
    "    #train_df['r2_'+feature] = np.round(train_df[feature], 2)\n",
    "    #test_df['r2_'+feature] = np.round(test_df[feature], 2)\n",
    "    #train_df['r1_'+feature] = np.round(train_df[feature], 1)\n",
    "    #test_df['r1_'+feature] = np.round(test_df[feature], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "514c57aec33654bfabe59204b1367eb19ac1cca0"
   },
   "source": [
    "Let's check how many features we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "783ac0da84eae3b48c27f317a957ebc2b48091e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test columns: 202 201\n"
     ]
    }
   ],
   "source": [
    "print('Train and test columns: {} {}'.format(len(train_df.columns), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac818e478d560bee541240eac9190ee5042eab48"
   },
   "source": [
    "# <a id='5'>Model</a>  \n",
    "\n",
    "From the train columns list, we drop the ID and target to form the features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "567d06495fb26ca26881c0fb9a8ef80b388ab901"
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e48d029f6bf9421e401c0b2e3bfe269dfbad4e8"
   },
   "source": [
    "We define the hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "8a57bca14c4c82fb80bafd0c27c42bf1a405b531"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 20.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e93df12ae1b6e514da38772132fb35ef048d8e73"
   },
   "source": [
    "We run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "595ba3944cb9365e292819afcd8406de8166bd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.883832\tvalid_1's auc: 0.865008\n",
      "[2000]\ttraining's auc: 0.896072\tvalid_1's auc: 0.872486\n",
      "[3000]\ttraining's auc: 0.904088\tvalid_1's auc: 0.876518\n",
      "[4000]\ttraining's auc: 0.910344\tvalid_1's auc: 0.879212\n",
      "[5000]\ttraining's auc: 0.915609\tvalid_1's auc: 0.880612\n",
      "[6000]\ttraining's auc: 0.920348\tvalid_1's auc: 0.881699\n",
      "[7000]\ttraining's auc: 0.924816\tvalid_1's auc: 0.882412\n",
      "[8000]\ttraining's auc: 0.928949\tvalid_1's auc: 0.882806\n",
      "[9000]\ttraining's auc: 0.932845\tvalid_1's auc: 0.882991\n",
      "[10000]\ttraining's auc: 0.936564\tvalid_1's auc: 0.882923\n",
      "[11000]\ttraining's auc: 0.94014\tvalid_1's auc: 0.883038\n",
      "[12000]\ttraining's auc: 0.94352\tvalid_1's auc: 0.882993\n",
      "[13000]\ttraining's auc: 0.946742\tvalid_1's auc: 0.882694\n",
      "[14000]\ttraining's auc: 0.949763\tvalid_1's auc: 0.882579\n",
      "Early stopping, best iteration is:\n",
      "[11101]\ttraining's auc: 0.940498\tvalid_1's auc: 0.883096\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70299b2aa81a678c0bee8ca183f064c82b673ba4"
   },
   "source": [
    "Let's check the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "9f989c0d69a89f3964265615b6c64ad6010cec37"
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94f2cac9789db26b27c88db136d1366c70b5cc33"
   },
   "source": [
    "# <a id='6'>Submission</a>  \n",
    "\n",
    "We submit the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "4c1965242e30db114a3a28d850fea148d34c06c9"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cac53504a582a6480206aa925928f4be435d0ac0"
   },
   "source": [
    "# <a id='7'>References</a>    \n",
    "\n",
    "[1] https://www.kaggle.com/gpreda/elo-world-high-score-without-blending  \n",
    "[2] https://www.kaggle.com/chocozzz/santander-lightgbm-baseline-lb-0-897  \n",
    "[3] https://www.kaggle.com/brandenkmurray/nothing-works\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b82fbe1cac93b01278ebef47951df65033cf2cc5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c916d778cf28bf35d16d0c71dcbadc83084cbeb4"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
